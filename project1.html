<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Projet 1 — Classification Multispectrale</title>
  <link rel="stylesheet" type="text/css" href="style.css/style.css" />
  <script defer src="js/JavaScript.js"></script>
  </head>

  <div class="BG1">
    <div class="wrapper">

      <body>

      <header>
        <div class="logo">
          <a href="index.html"><img src="images/Logo.png" width="268pt" height="101pt"></img></a>
        </div>
        <div class="Menu">
          <nav>
            <ul>
              <li>
                <a href="Planets.html">Planets</a>
                <ul class="submenu">
                  <li><a href="Planets.html#Mercure">Mercure</a></li>
                  <li><a href="Planets.html#Venus">Vénus</a></li>
                  <li><a href="Planets.html#Terre">Terre</a></li>
                  <li><a href="Planets.html#Mercure">Mars</a></li>
                  <li><a href="Planets.html#Jupiter">Jupiter</a></li>
                  <li><a href="Planets.html#Saturne">Saturne</a></li>
                  <li><a href="Planets.html#Uranus">Uranus</a></li>
                  <li><a href="Planets.html#Neptune">Neptune</a></li>
                </ul>
              </li>

              <li>
                <a href="Stars.html">Stars</a>
                <ul class="submenu">
                  <li><a href="Stars.html#Stars">Stars</a></li>
                  <li><a href="Stars.html#Close Stars">Close Stars</a></li>
                  <li><a href="Stars.html#The Sun">The sun</a></li>
                  <li><a href="Stars.html#Constellations">Constellations</a></li>
                  <li><a href="Stars.html#Pulsars">Pulsars</a></li>
                  <li><a href="Stars.html#Supernova">Supernova</a></li>

                </ul>
              </li>
              <li>
                <a href="Galaxy.html">Galaxy</a>
                <ul class="submenu">
                  <li><a href="Galaxy.html#Galaxy">Galaxy</a></li>
                  <li><a href="Galaxy.html#Mily Way">Milky Way</a></li>
                  <li><a href="Galaxy.html#Black Hole">Black Hole</a></li>
                  <li><a href="Galaxy.html#Quasars">Quasars</a></li>
                </ul>
              </li>
              <li>
                <a href="Earth Obs. & ML.html">Earth Obs. & ML</a>
                <ul class="submenu">
                  <li><a href="Earth Obs. & ML.html#Overview">Overview</a></li>
                  <li><a href="Earth Obs. & ML.html#Satellite">Satellite Technology</a></li>
                  <li><a href="Earth Obs. & ML.html#Machine Learning">Machine Learning</a></li>
                  <li><a href="Earth Obs. & ML.html#Applications">Applications</a></li>
                </ul>
              </li>
            </ul>

          </nav>

        </div>
      </header>
<main>
    <h1>Segmentation Sémantique – U-Net sur Images Satellite</h1>

    <p><strong>Résumé :</strong> 
      Ce projet met en œuvre un modèle <strong>U-Net</strong> pour réaliser la 
      <strong>segmentation sémantique</strong> d’images Sentinel-2. 
      L’objectif est d’identifier automatiquement différentes classes d’occupation 
      du sol (zones urbaines, végétation, eau) à partir de données multispectrales.
    </p>

    <p><strong>Compétences démontrées :</strong> 
      prétraitement raster (<em>rasterio, GDAL</em>), extraction multispectrale 
      (RGB/NIR/SWIR), création de patches d’apprentissage, entraînement d’un 
      <strong>CNN U-Net</strong> sous <strong>PyTorch</strong>, métriques IoU/F1.
    </p>

    <section>
      <h2>Données</h2>
      <ul>
        <li><strong>Source :</strong> Sentinel-2 L2A (Copernicus)</li>
        <li><strong>Bands utilisées :</strong> B2, B3, B4, B8 (visible & NIR), B11/B12 (SWIR)</li>
        <li><strong>Résolution :</strong> 10–20 m</li>
        <li><strong>Prétraitement :</strong> reprojection, normalisation, cloud masking, 
            extraction de patches 128×128</li>
      </ul>
    </section>

    <section>
      <h2>Méthodologie</h2>
      <ul>
        <li>
          <strong>Prétraitement :</strong> ouverture des bandes Sentinel-2 avec <em>rasterio</em>, 
          stacking multispectral, harmonisation des résolutions, 
          calcul d’indices (NDVI/NDWI).
        </li>
        <li>
          <strong>Dataset :</strong> génération de milliers de patches multispectraux et 
          extraction des masques d’occupation du sol (open-source / OSM / Inria).
        </li>
        <li>
          <strong>Modèle :</strong> architecture <strong>U-Net</strong> avec encodeur 
          type <em>ResNet-34</em>.
        </li>
        <li>
          <strong>Entraînement :</strong> PyTorch, augmentation géospatiale 
          (rotation, flip, brightness), fonction de perte <em>Dice + BCE</em>.
        </li>
        <li>
          <strong>Évaluation :</strong> IoU par classe, F1-score, matrice de confusion.
        </li>
      </ul>
    </section>

    <section>
      <h2>Résultats</h2>
      <p>
        Le modèle atteint une <strong>IoU moyenne de XX%</strong> sur le jeu de test.  
        La segmentation permet de distinguer efficacement zones urbaines, végétation 
        dense et surfaces d’eau.
      </p>

      <div class="image-grid">
        <figure>
          <img src="images/input_example.jpg" 
               alt="Image satellite brute" 
               style="max-width:100%;border-radius:8px;">
          <figcaption>Image multispectrale d’entrée</figcaption>
        </figure>

        <figure>
          <img src="images/output_unet.jpg" 
               alt="Segmentation U-Net" 
               style="max-width:100%;border-radius:8px;">
          <figcaption>Résultat de la segmentation (U-Net)</figcaption>
        </figure>
      </div>
    </section>

    <section>
      <h2>Technologies utilisées</h2>
      <ul>
        <li><strong>Python scientifique :</strong> NumPy, Pandas, Matplotlib</li>
        <li><strong>Traitement d’images :</strong> rasterio, GDAL</li>
        <li><strong>Machine Learning :</strong> PyTorch, TensorFlow</li>
        <li><strong>Analyse géospatiale :</strong> geopandas, QGIS</li>
      </ul>
    </section>

    <section>
      <h2>Ce que ce projet démontre</h2>
      <p>
        Ce projet illustre ma capacité à développer un pipeline complet de 
        <strong>vision par ordinateur appliquée à l’observation de la Terre</strong>, 
        depuis la préparation des données brutes Sentinel-2 jusqu’à la mise en production 
        d’un modèle de segmentation <strong>U-Net</strong>.  
        Il met également en valeur mes compétences en <strong>traitement d’images</strong>, 
        <strong>machine learning</strong> et <strong>exploitation de données multispectrales</strong>, 
        telles que décrites dans mon CV.
      </p>
    </section>

    <p><a href="Earth Obs. & ML.html" class="btn">← Retour à Earth Obs. & ML</a></p>
</main>

      <footer>&copy; Pierre BAUDU 2021</footer>
    </div>
  </div>
</body>
</html>
          </nav>

        </div>
      </header>

